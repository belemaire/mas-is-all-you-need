import re
import os
from aisuite import Client as aisuite_client
from openai import OpenAI
from typing import List
from chromadb import HttpClient as chromadb_http_client
from tqdm import tqdm
from uuid import uuid5, NAMESPACE_DNS
from dotenv import load_dotenv
from argparse import ArgumentParser
from cachier import cachier
from json import dumps
from datetime import datetime, timezone
from prompts import PROMPT_TEXT_CHUNKING


def get_txt_file_content(path: str) -> str:
    """
    Reads the content of a text file and returns it as a string.

    Args:
        path (str): The path to the text file.

    Returns:
        str: The content of the text file.
    """
    with open(path, "r") as file:
        return file.read()


@cachier(cache_dir='.cachier')
def process_text(
    text : str, 
    system_prompt : str = PROMPT_TEXT_CHUNKING, 
    model : str = "openai:gpt-4o-mini", 
    temperature : float = 0.7
) -> str:
    """
    Process the input text using a specified AI model and return the generated 
    content.

    This function sends the input text to an AI model for processing, using a 
    specified system prompt, and returns the generated response.

    Args:
        text (str): The input text to be processed.
        system_prompt (str, optional): The system prompt to guide the AI's 
        behavior. 
            Defaults to PROMPT_TEXT_CHUNKING.
        model (str, optional): The AI model to use for processing. 
            Defaults to "openai:gpt-4o-mini".
        temperature (float, optional): The temperature setting for the AI 
            model's output. Higher values make the output more random, lower 
            values make it more deterministic. 
            Defaults to 0.7.

    Returns:
        str: The content generated by the AI model in response to the input text.
    """
    client = aisuite_client()
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": text},
    ]
    response = client.chat.completions.create(
        model = model,
        messages = messages,
        temperature = temperature
    )
    return response.choices[0].message.content


def text_to_list(text : str) -> List[str]:
    """
    Extract content from <chunk> tags in the given text and return it as a list.

    This function uses a regular expression to find all occurrences of content
    enclosed within <chunk> tags in the input text. It returns a list where each
    element is the content of a <chunk> tag.

    Args:
        text (str): The input string containing <chunk> tags.

    Returns:
        List[str]: A list of strings, where each string is the content found 
        between <chunk> tags. If no matches are found, returns an empty list.
    """
    pattern = r'<chunk>(.*?)</chunk>'
    return re.findall(pattern, text, re.DOTALL)


@cachier(cache_dir='.cachier')
def get_embedding(
    list_text : List[str], 
    model : str = 'text-embedding-3-small', 
) -> List[float]:
    """
    Generate embeddings for a list of text strings using OpenAI's API.

    This function takes a list of text strings and returns their corresponding
    embeddings using the specified OpenAI model. It uses the OpenAI API to
    generate embeddings for each text string in the input list.

    Args:
        list_text (List[str]): A list of text strings to be embedded.
        model (str, optional): The name of the OpenAI embedding model to use.
            Defaults to 'text-embedding-3-small'.

    Returns:
        List[float]: A list of embedding vectors, where each vector is 
        represented as a list of floats. The length of the outer list matches 
        the length of the input list_text.
    """
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    emb_output = client.embeddings.create(
        input = list_text, 
        model = model
    )
    return [emb_output.data[j].embedding for j in range(len(emb_output.data))]


def save_chunks_to_db(
    chunks : List[str], 
    chunks_source : str = "",
    chroma_db_host : str = "", 
    chroma_db_port : int = -1, 
    collection_name : str = "chunks"
) -> None:
    """
    Save text chunks to a ChromaDB collection with their embeddings.

    This function takes a list of text chunks, generates embeddings for them,
    and saves them to a specified ChromaDB collection. It also assigns unique
    IDs to each chunk and adds metadata about the source of the chunks.

    Args:
        chunks (List[str]): A list of text chunks to be saved.
        chunks_source (str, optional): The source of the chunks for metadata. 
            Defaults to an empty string.
        chroma_db_host (str, optional): The host address of the ChromaDB server. 
            If not provided, it uses the CHROMA_DB_HOST environment variable or 
            defaults to 'localhost'.
        chroma_db_port (int, optional): The port number of the ChromaDB server. 
            If not provided, it uses the CHROMA_DB_PORT environment variable or 
            defaults to 8001.
        collection_name (str, optional): The name of the ChromaDB collection to 
            use. Defaults to "chunks".

    Returns:
        None
    """
    if len(chroma_db_host) == 0:
        chroma_db_host = os.getenv('CHROMA_DB_HOST', 'localhost')
    if chroma_db_port < 0:
        chroma_db_port = int(os.getenv('CHROMA_DB_PORT', 8001))
    client = chromadb_http_client(
        host=chroma_db_host, 
        port=chroma_db_port
    )
    collection = client.get_or_create_collection(name=collection_name)
    tms_now = datetime.now(timezone.utc).strftime("%d %B %Y %H:%M:%S")
    collection.add(
        ids=[str(uuid5(NAMESPACE_DNS, chunk)) for chunk in chunks],
        embeddings=get_embedding(list_text=chunks),
        documents=chunks, 
        metadatas=[
            {'chunk_source': chunks_source, "last_update": tms_now} \
            for _ in range(len(chunks))
        ]
    )


def delete_collection(
    chroma_db_host : str = "", 
    chroma_db_port : int = -1, 
    collection_name : str = "chunks"
) -> None:
    """
    Delete a specified collection from a ChromaDB instance.

    This function attempts to delete a collection from a ChromaDB server. It uses
    environment variables for the host and port if not provided explicitly.

    Args:
        chroma_db_host (str, optional): The host address of the ChromaDB server. 
            If not provided, it uses the CHROMA_DB_HOST environment variable or 
            defaults to 'localhost'.
        chroma_db_port (int, optional): The port number of the ChromaDB server. 
            If not provided, it uses the CHROMA_DB_PORT environment variable or 
            defaults to 8001.
        collection_name (str, optional): The name of the ChromaDB collection to 
            delete. Defaults to "chunks".

    Returns:
        None
    """
    if len(chroma_db_host) == 0:
        chroma_db_host = os.getenv('CHROMA_DB_HOST', 'localhost')
    if chroma_db_port < 0:
        chroma_db_port = int(os.getenv('CHROMA_DB_PORT', 8001))
    client = chromadb_http_client(
        host=chroma_db_host, 
        port=chroma_db_port
    )
    try:
        client.delete_collection(name=collection_name)
        print("Collection %s deleted successfully." % collection_name)
    except Exception as e:
        print("Failed to delete collection %s. %s" % (collection_name, e))


def path_to_db(path : str) -> str:
    """
    Process a text file and save its chunks to a database.

    This function performs the following steps:
    1. Loads environment variables
    2. Reads the content of a text file specified by the path
    3. Processes the text to create chunks
    4. Converts the processed text into a list of chunks
    5. Saves the chunks to a database with the file path as the source

    Args:
        path (str): The file path of the text file to be processed and saved.

    Returns:
        str: Saved chunks.
    """
    load_dotenv()
    text = get_txt_file_content(path=path)
    text_chunks = process_text(text=text)
    list_chunks = text_to_list(text=text_chunks)
    save_chunks_to_db(chunks=list_chunks, chunks_source=path)
    print("File %s chunked and saved to DB." % (path))
    return dumps(list_chunks, indent=4)


def text_to_db(text : str) -> str:
    """
    Process a given text and save its chunks to a database.

    This function performs the following steps:
    1. Loads environment variables
    2. Processes the input text to create chunks
    3. Converts the processed text into a list of chunks
    4. Saves the chunks to a database without specifying a source

    Args:
        text (str): The input text to be processed and saved.

    Returns:
        str: Saved chunks.
    """
    load_dotenv()
    text_chunks = process_text(text=text)
    list_chunks = text_to_list(text=text_chunks)
    save_chunks_to_db(chunks=list_chunks, chunks_source="")
    print("Text chunked and saved to DB.")
    return dumps(list_chunks, indent=4)


if __name__ == "__main__":
    parser = ArgumentParser(
        description='Chunk a txt file and save the chunks to a database'
    )
    parser.add_argument(
        '--path', type=str, help='The path of the txt file', required=True
    )
    parser.add_argument(
        '--reset', type=str, help='Reset the collection.', default="False", 
    )
    args = parser.parse_args()
    load_dotenv()
    if str(args.reset) == "True":
        print("Deleting the collection before starting.")
        delete_collection()
    path_to_db(path=args.path)
    